{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Iris MLOps \u2013 Project Documentation This project demonstrates a complete MLOps pipeline built around a simple Iris classification model. It includes: Model training and experiment tracking with MLflow A FastAPI backend exposing a /predict endpoint A Streamlit frontend UI for predictions Docker images for backend & frontend A CI/CD pipeline with GitHub Actions Deployment to Azure App Service 1. Project Structure Main folders: backend/ app/ FastAPI application (API) ml/ Model training script with MLflow model/ Trained model file (iris_model.pkl) tests/ Backend tests (pytest) requirements.txt Backend dependencies frontend/ app.py Streamlit app requirements.txt Frontend dependencies docs/ index.md This documentation (MkDocs) .github/workflows/ ci-cd.yml CI/CD pipeline (tests, docs, Docker build & push) 2. How to Get Started This section explains how to set up your environment and install all required dependencies. 2.1 Prerequisites You need: Python 3.11+ A virtual environment pip Docker (optional) Git Create and activate your environment: cd iris-ml-cicd python -m venv .venv source .venv/bin/activate Install dependencies: pip install -r backend/requirements.txt pip install -r frontend/requirements.txt pip install mkdocs mkdocs-material 3. MLflow & Model Training 3.1 Start MLflow UI mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns MLflow UI is available at: http://127.0.0.1:5000 3.2 Train the Model The training script: loads the Iris dataset trains a LogisticRegression model logs parameters & metrics to MLflow saves the trained model to backend/model/iris_model.pkl Run: python -m backend.ml.train After training, the file iris_model.pkl should appear inside: backend/model/ 4. Run the Backend (FastAPI) The backend exposes: GET / \u2192 health check POST /predict \u2192 returns the predicted Iris class Run locally: uvicorn backend.app.main:app --reload --port 8001 Backend available at: http://127.0.0.1:8001 http://127.0.0.1:8001/docs 5. Run the Frontend (Streamlit) The frontend: lets you input the 4 Iris features sends a request to /predict displays the predicted class Default backend URL: BACKEND_URL = os.getenv(\"BACKEND_URL\", \"http://localhost:8001\") Run: cd frontend streamlit run app.py Frontend available at: http://127.0.0.1:8501 6. Run Everything with Docker 6.1 Build Docker images docker build -t mlops-demo-backend:local ./backend docker build -t mlops-demo-frontend:local ./frontend 6.2 Run containers Backend: docker run -p 8001:8001 mlops-demo-backend:local Frontend (with backend connection): docker run -p 8501:8501 \\ -e BACKEND_URL=\"http://host.docker.internal:8001\" \\ mlops-demo-frontend:local 7. CI/CD Pipeline (GitHub Actions) The CI/CD pipeline ( .github/workflows/ci-cd.yml ) runs on each push to main : installs backend dependencies runs backend tests builds and deploys documentation builds Docker images (backend + frontend) pushes images to Docker Hub Secrets required: DOCKERHUB_USERNAME DOCKERHUB_TOKEN Configured in: GitHub \u2192 Settings \u2192 Secrets and Variables \u2192 Actions 8. Deployment on Azure Backend Runs as a Docker App Service Port: 8001 Image: DOCKERHUB_USER/mlops-demo-backend:latest Accessible at: https://iris-backend-app-fggsfndcfteqatbm.francecentral-01.azurewebsites.net https://iris-backend-app-fggsfndcfteqatbm.francecentral-01.azurewebsites.net/docs Frontend Runs as a Docker App Service Port: 8501 Requires environment variable: BACKEND_URL = https://iris-backend-app-fggsfndcfteqatbm.francecentral-01.azurewebsites.net Accessible at: https://iris-frontend-app-gtbdgddpgedqdybk.francecentral-01.azurewebsites.net 9. Summary This project demonstrates a complete MLOps workflow: ML training and experiment tracking FastAPI model serving Streamlit user interface Dockerization CI/CD automation with GitHub Actions Deployment to Azure App Service","title":"Project"},{"location":"#iris-mlops-project-documentation","text":"This project demonstrates a complete MLOps pipeline built around a simple Iris classification model. It includes: Model training and experiment tracking with MLflow A FastAPI backend exposing a /predict endpoint A Streamlit frontend UI for predictions Docker images for backend & frontend A CI/CD pipeline with GitHub Actions Deployment to Azure App Service","title":"Iris MLOps \u2013 Project Documentation"},{"location":"#1-project-structure","text":"Main folders: backend/ app/ FastAPI application (API) ml/ Model training script with MLflow model/ Trained model file (iris_model.pkl) tests/ Backend tests (pytest) requirements.txt Backend dependencies frontend/ app.py Streamlit app requirements.txt Frontend dependencies docs/ index.md This documentation (MkDocs) .github/workflows/ ci-cd.yml CI/CD pipeline (tests, docs, Docker build & push)","title":"1. Project Structure"},{"location":"#2-how-to-get-started","text":"This section explains how to set up your environment and install all required dependencies.","title":"2. How to Get Started"},{"location":"#21-prerequisites","text":"You need: Python 3.11+ A virtual environment pip Docker (optional) Git Create and activate your environment: cd iris-ml-cicd python -m venv .venv source .venv/bin/activate Install dependencies: pip install -r backend/requirements.txt pip install -r frontend/requirements.txt pip install mkdocs mkdocs-material","title":"2.1 Prerequisites"},{"location":"#3-mlflow-model-training","text":"","title":"3. MLflow &amp; Model Training"},{"location":"#31-start-mlflow-ui","text":"mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns MLflow UI is available at: http://127.0.0.1:5000","title":"3.1 Start MLflow UI"},{"location":"#32-train-the-model","text":"The training script: loads the Iris dataset trains a LogisticRegression model logs parameters & metrics to MLflow saves the trained model to backend/model/iris_model.pkl Run: python -m backend.ml.train After training, the file iris_model.pkl should appear inside: backend/model/","title":"3.2 Train the Model"},{"location":"#4-run-the-backend-fastapi","text":"The backend exposes: GET / \u2192 health check POST /predict \u2192 returns the predicted Iris class Run locally: uvicorn backend.app.main:app --reload --port 8001 Backend available at: http://127.0.0.1:8001 http://127.0.0.1:8001/docs","title":"4. Run the Backend (FastAPI)"},{"location":"#5-run-the-frontend-streamlit","text":"The frontend: lets you input the 4 Iris features sends a request to /predict displays the predicted class Default backend URL: BACKEND_URL = os.getenv(\"BACKEND_URL\", \"http://localhost:8001\") Run: cd frontend streamlit run app.py Frontend available at: http://127.0.0.1:8501","title":"5. Run the Frontend (Streamlit)"},{"location":"#6-run-everything-with-docker","text":"","title":"6. Run Everything with Docker"},{"location":"#61-build-docker-images","text":"docker build -t mlops-demo-backend:local ./backend docker build -t mlops-demo-frontend:local ./frontend","title":"6.1 Build Docker images"},{"location":"#62-run-containers","text":"Backend: docker run -p 8001:8001 mlops-demo-backend:local Frontend (with backend connection): docker run -p 8501:8501 \\ -e BACKEND_URL=\"http://host.docker.internal:8001\" \\ mlops-demo-frontend:local","title":"6.2 Run containers"},{"location":"#7-cicd-pipeline-github-actions","text":"The CI/CD pipeline ( .github/workflows/ci-cd.yml ) runs on each push to main : installs backend dependencies runs backend tests builds and deploys documentation builds Docker images (backend + frontend) pushes images to Docker Hub Secrets required: DOCKERHUB_USERNAME DOCKERHUB_TOKEN Configured in: GitHub \u2192 Settings \u2192 Secrets and Variables \u2192 Actions","title":"7. CI/CD Pipeline (GitHub Actions)"},{"location":"#8-deployment-on-azure","text":"","title":"8. Deployment on Azure"},{"location":"#backend","text":"Runs as a Docker App Service Port: 8001 Image: DOCKERHUB_USER/mlops-demo-backend:latest Accessible at: https://iris-backend-app-fggsfndcfteqatbm.francecentral-01.azurewebsites.net https://iris-backend-app-fggsfndcfteqatbm.francecentral-01.azurewebsites.net/docs","title":"Backend"},{"location":"#frontend","text":"Runs as a Docker App Service Port: 8501 Requires environment variable: BACKEND_URL = https://iris-backend-app-fggsfndcfteqatbm.francecentral-01.azurewebsites.net Accessible at: https://iris-frontend-app-gtbdgddpgedqdybk.francecentral-01.azurewebsites.net","title":"Frontend"},{"location":"#9-summary","text":"This project demonstrates a complete MLOps workflow: ML training and experiment tracking FastAPI model serving Streamlit user interface Dockerization CI/CD automation with GitHub Actions Deployment to Azure App Service","title":"9. Summary"}]}